{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":14488677,"sourceType":"datasetVersion","datasetId":9254136}],"dockerImageVersionId":31234,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Step 1: Import Libraries ","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.pipeline import Pipeline\n\nfrom sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n\n# didn't add LabEncoded since dataset used is already numerical","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-13T20:19:12.926394Z","iopub.execute_input":"2026-01-13T20:19:12.926584Z","iopub.status.idle":"2026-01-13T20:19:13.660971Z","shell.execute_reply.started":"2026-01-13T20:19:12.926567Z","shell.execute_reply":"2026-01-13T20:19:13.660241Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Step 2: Link/Upload Dataset\n\n","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/wildfire/final_dataset.csv\")\n\nprint(\"Shape:\", df.shape)\ndisplay(df.head())\nprint(df.columns)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T20:19:13.662078Z","iopub.execute_input":"2026-01-13T20:19:13.662519Z","iopub.status.idle":"2026-01-13T20:19:13.860455Z","shell.execute_reply.started":"2026-01-13T20:19:13.662501Z","shell.execute_reply":"2026-01-13T20:19:13.859613Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Step 3: Fix the Data","metadata":{}},{"cell_type":"code","source":"df.tail()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T20:19:13.861563Z","iopub.execute_input":"2026-01-13T20:19:13.861850Z","iopub.status.idle":"2026-01-13T20:19:13.875261Z","shell.execute_reply.started":"2026-01-13T20:19:13.861826Z","shell.execute_reply":"2026-01-13T20:19:13.874579Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T20:19:13.876768Z","iopub.execute_input":"2026-01-13T20:19:13.876982Z","iopub.status.idle":"2026-01-13T20:19:13.898750Z","shell.execute_reply.started":"2026-01-13T20:19:13.876964Z","shell.execute_reply":"2026-01-13T20:19:13.898097Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T20:19:13.899459Z","iopub.execute_input":"2026-01-13T20:19:13.899644Z","iopub.status.idle":"2026-01-13T20:19:14.007198Z","shell.execute_reply.started":"2026-01-13T20:19:13.899630Z","shell.execute_reply":"2026-01-13T20:19:14.006372Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Step 4: Define X (features) and y (target)\nSets the prediction target (occured) and builds the input features by dropping occured and frp","metadata":{}},{"cell_type":"code","source":"y = df[\"occured\"].astype(int)\n\n# Drop target + leakage column\nX = df.drop(columns=[\"occured\", \"frp\"])\n\nprint(\"X shape:\", X.shape)\nprint(\"y distribution:\\n\", y.value_counts())\n\n# Fill missing numeric values using the median so KNN can run without errors\nX = X.fillna(X.median(numeric_only=True))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T20:19:14.007888Z","iopub.execute_input":"2026-01-13T20:19:14.008036Z","iopub.status.idle":"2026-01-13T20:19:14.049701Z","shell.execute_reply.started":"2026-01-13T20:19:14.008024Z","shell.execute_reply":"2026-01-13T20:19:14.049078Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Step 5: Spitting the Data","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42, stratify=y\n)\n\nprint(\"Train:\", X_train.shape, \"Test:\", X_test.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T20:19:14.050365Z","iopub.execute_input":"2026-01-13T20:19:14.050576Z","iopub.status.idle":"2026-01-13T20:19:14.099910Z","shell.execute_reply.started":"2026-01-13T20:19:14.050562Z","shell.execute_reply":"2026-01-13T20:19:14.099217Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Step 6: Train the KNN model (with scaling)\nScales the data (important for KNN) and trains the classifier.\nNote: scaling is important if dealing with big and small numbers.","metadata":{}},{"cell_type":"code","source":"knn_model = Pipeline([\n    (\"scaler\", StandardScaler()),\n    (\"knn\", KNeighborsClassifier(n_neighbors=15))\n])\n\nknn_model.fit(X_train, y_train)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T20:19:14.100730Z","iopub.execute_input":"2026-01-13T20:19:14.101503Z","iopub.status.idle":"2026-01-13T20:19:14.335727Z","shell.execute_reply.started":"2026-01-13T20:19:14.101468Z","shell.execute_reply":"2026-01-13T20:19:14.335169Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Step 7: Test (predict on the test set)\nUses the trained model to predict labels for unseen test data.","metadata":{}},{"cell_type":"code","source":"y_pred = knn_model.predict(X_test)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T20:19:14.336419Z","iopub.execute_input":"2026-01-13T20:19:14.336607Z","iopub.status.idle":"2026-01-13T20:19:29.065026Z","shell.execute_reply.started":"2026-01-13T20:19:14.336594Z","shell.execute_reply":"2026-01-13T20:19:29.064378Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Step 8: Accuracy ","metadata":{}},{"cell_type":"code","source":"acc = accuracy_score(y_test, y_pred)\nprint(\"Test Accuracy:\", acc)\n\ncm = confusion_matrix(y_test, y_pred)\nprint(\"Confusion Matrix:\\n\", cm)\n\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"No Fire\", \"Fire\"])\ndisp.plot()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T20:19:29.066788Z","iopub.execute_input":"2026-01-13T20:19:29.066960Z","iopub.status.idle":"2026-01-13T20:19:29.193773Z","shell.execute_reply.started":"2026-01-13T20:19:29.066947Z","shell.execute_reply":"2026-01-13T20:19:29.193152Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Step 9: Tune K and compare improvement\nTests multiple k values, finds the best one, plots accuracy vs k, then retrains using the best k and prints the new accuracy.","metadata":{}},{"cell_type":"code","source":"k_values = [1,3,5,7,9,11,15,21,31,41,51]\naccs = []\n\nfor k in k_values:\n    model = Pipeline([\n        (\"scaler\", StandardScaler()),\n        (\"knn\", KNeighborsClassifier(n_neighbors=k))\n    ])\n    model.fit(X_train, y_train)\n    pred = model.predict(X_test)\n    accs.append(accuracy_score(y_test, pred))\n\nbest_k = k_values[int(np.argmax(accs))]\nbest_acc = max(accs)\n\nprint(\"K values tested:\", k_values)\nprint(\"Accuracies:\", accs)\nprint(\"Best K:\", best_k)\nprint(\"Best Test Accuracy:\", best_acc)\n\nplt.figure()\nplt.plot(k_values, accs, marker=\"o\")\nplt.xlabel(\"k (number of neighbors)\")\nplt.ylabel(\"Test Accuracy\")\nplt.title(\"KNN Accuracy vs k\")\nplt.show()\n\n# Retrain final tuned KNN and store predictions for later evaluation (confusion matrix etc.)\nknn_model_tuned = Pipeline([\n    (\"scaler\", StandardScaler()),\n    (\"knn\", KNeighborsClassifier(n_neighbors=best_k))\n])\nknn_model_tuned.fit(X_train, y_train)\n\ny_pred_tuned = knn_model_tuned.predict(X_test)\n\nprint(\"Tuned KNN Test Accuracy:\", accuracy_score(y_test, y_pred_tuned))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T20:19:29.194452Z","iopub.execute_input":"2026-01-13T20:19:29.194679Z","iopub.status.idle":"2026-01-13T20:21:56.916025Z","shell.execute_reply.started":"2026-01-13T20:19:29.194661Z","shell.execute_reply":"2026-01-13T20:21:56.915264Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Step 10: Train a Random Forest Model (to see if we get better accuracy)\nTrains a Random Forest classifier (many decision trees voting together) to capture non-linear patterns in the weather data. It often performs better than KNN on tabular datasets.","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\nimport matplotlib.pyplot as plt\n\n# Step 9: Random Forest (Optional Improvement Step)\n# Trains many decision trees and combines them to improve prediction accuracy\n\nrf_model = RandomForestClassifier(\n    n_estimators=400,\n    random_state=42,\n    n_jobs=-1\n)\n\nrf_model.fit(X_train, y_train)\n\ny_pred_rf = rf_model.predict(X_test)\n\nprint(\"Random Forest Test Accuracy:\", accuracy_score(y_test, y_pred_rf))\n\n# Confusion Matrix Visualization\ncm_rf = confusion_matrix(y_test, y_pred_rf)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm_rf, display_labels=[\"No Fire\", \"Fire\"])\ndisp.plot()\nplt.title(\"Random Forest Confusion Matrix\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T20:26:30.953661Z","iopub.execute_input":"2026-01-13T20:26:30.954366Z","iopub.status.idle":"2026-01-13T20:27:13.578862Z","shell.execute_reply.started":"2026-01-13T20:26:30.954351Z","shell.execute_reply":"2026-01-13T20:27:13.578196Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Step 11: Using HistGradientBoosting (Best Tabular Model)\nTrying this model to see if accuracy improves, which allows us to compare which model is best suited to predict wildfire.","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import HistGradientBoostingClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\nimport matplotlib.pyplot as plt\n\n# Step 11: Tune HistGradientBoosting (Optional)\n# Tries different settings to see if boosting can beat Random Forest\n\nparam_grid = {\n    \"learning_rate\": [0.03, 0.05, 0.1],\n    \"max_depth\": [3, 5, 7, None],\n    \"max_iter\": [200, 400, 600]\n}\n\nhgb = HistGradientBoostingClassifier(random_state=42)\ngrid = GridSearchCV(hgb, param_grid, scoring=\"accuracy\", cv=3, n_jobs=-1)\ngrid.fit(X_train, y_train)\n\nprint(\"Best params:\", grid.best_params_)\nbest_hgb = grid.best_estimator_\n\ny_pred_best_hgb = best_hgb.predict(X_test)\nprint(\"Tuned HGB Test Accuracy:\", accuracy_score(y_test, y_pred_best_hgb))\n\ncm = confusion_matrix(y_test, y_pred_best_hgb)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"No Fire\", \"Fire\"])\ndisp.plot()\nplt.title(\"Tuned HistGradientBoosting Confusion Matrix\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T20:27:21.073015Z","iopub.execute_input":"2026-01-13T20:27:21.073240Z","iopub.status.idle":"2026-01-13T20:28:49.184254Z","shell.execute_reply.started":"2026-01-13T20:27:21.073227Z","shell.execute_reply":"2026-01-13T20:28:49.183455Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Step 12: Compare all 3 models\nThis showcases which model was the most accurate.","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nresults = {\n    \"KNN (tuned k)\": 0.6497139491839139,\n    \"Random Forest\": 0.6678865892646811,\n    \"HistGradientBoosting (tuned)\": 0.6559818273599193\n}\n\nmodels = list(results.keys())\nscores = list(results.values())\n\nbest_model = max(results, key=results.get)\nbest_score = results[best_model]\n\nplt.figure(figsize=(8,4))\nbars = plt.bar(models, scores)\n\nplt.ylim(0.5, 0.75)\nplt.ylabel(\"Test Accuracy\")\nplt.title(\"Model Comparison (Test Accuracy)\")\n\n# Add value labels above bars\nfor i, v in enumerate(scores):\n    plt.text(i, v + 0.003, f\"{v:.3f}\", ha=\"center\")\n\nplt.xticks(rotation=15, ha=\"right\")\nplt.show()\n\nprint(f\"Best model: {best_model} with accuracy = {best_score:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T20:29:35.402481Z","iopub.execute_input":"2026-01-13T20:29:35.402926Z","iopub.status.idle":"2026-01-13T20:29:35.511826Z","shell.execute_reply.started":"2026-01-13T20:29:35.402912Z","shell.execute_reply":"2026-01-13T20:29:35.511060Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Conclusion\nModel comparison: We trained three classifiers (KNN, Random Forest, and HistGradientBoosting) on the same 80/20 split and compared their test accuracy. Random Forest achieved the best performance (0.668), followed by HistGradientBoosting (0.656) and KNN (0.650). The overall accuracy is moderate because wildfire occurrence cannot be explained by weather variables aloneâ€”fires are also influenced by ignition sources (human activity/lightning), vegetation and fuel conditions, and local geographyâ€”so the classes overlap and the model cannot perfectly separate â€œfireâ€ vs â€œno fireâ€ using the available features.","metadata":{}},{"cell_type":"markdown","source":"# Adjustable Weather Conditions to Check Fire Likelihood\nThis allows us to check how likely it is for a fire to happen based on weather conditions.","metadata":{}},{"cell_type":"code","source":"# GUI (Day/Night theme + clean radio colors + rounded slider steps + % output)\n\nimport numpy as np\nimport pandas as pd\nimport gradio as gr\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Load dataset\ntry:\n    df\nexcept NameError:\n    df = pd.read_csv(\"/kaggle/input/wildfire/final_dataset.csv\") \n\n# Prepare X/y\nif \"occured\" not in df.columns:\n    raise ValueError(\"Couldn't find 'occured' column. Check df.columns.\")\n\ndrop_cols = [\"occured\"] + ([\"frp\"] if \"frp\" in df.columns else [])\ny = df[\"occured\"].astype(int)\nX = df.drop(columns=drop_cols)\nX = X.fillna(X.median(numeric_only=True))\n\n# Split\ntry:\n    X_train, X_test, y_train, y_test\nexcept NameError:\n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=0.2, random_state=42, stratify=y\n    )\n\n# Train model\ntry:\n    rf_model\nexcept NameError:\n    rf_model = RandomForestClassifier(n_estimators=400, random_state=42, n_jobs=-1)\n    rf_model.fit(X_train, y_train)\n\nfeature_cols = X_train.columns.tolist()\nhas_daynight = \"daynight_N\" in feature_cols\n\n# Weather-only sliders (exclude lat/lon + exclude wind mean)\nexclude_cols = {\"lat\", \"lon\"}\nweather_keywords = [\n    \"temp\", \"humidity\", \"rh\", \"wind\", \"precip\", \"rain\",\n    \"pressure\", \"dewpoint\", \"cloud\", \"fwi\", \"fire_weather_index\"\n]\n\nweather_cols = [\n    c for c in feature_cols\n    if c.lower() not in exclude_cols\n    and c != \"daynight_N\"\n    and any(k in c.lower() for k in weather_keywords)\n]\n\npreferred_order = [\n    \"temp_mean\", \"temp_max\", \"temp_min\",\n    \"humidity_min\", \"humidity_mean\", \"humidity_max\",\n    \"wind_speed_max\",            # keep max wind\n    # \"wind_speed_mean\",         # intentionally removed\n    \"precip_mean\",\n    \"pressure_mean\",\n    \"dewpoint_mean\",\n    \"cloud_cover_mean\",\n    \"fire_weather_index\"\n]\n\nordered_weather = [c for c in preferred_order if c in weather_cols]\nordered_weather += [c for c in weather_cols if c not in ordered_weather]\n\n# Explicitly remove wind mean if it exists\nordered_weather = [c for c in ordered_weather if c != \"wind_speed_mean\"]\n\nslider_features = ordered_weather[:8]  # scroll is OK\n\nif len(slider_features) == 0:\n    raise ValueError(\"No weather-like columns found for sliders. Check df.columns.\")\n\nfriendly_label = {\n    \"temp_mean\": \"Average Temperature (Â°C)\",\n    \"temp_max\": \"Maximum Temperature (Â°C)\",\n    \"temp_min\": \"Minimum Temperature (Â°C)\",\n\n    \"humidity_mean\": \"Average Humidity (%)\",\n    \"humidity_min\": \"Minimum Humidity (%)\",\n    \"humidity_max\": \"Maximum Humidity (%)\",\n\n    \"wind_speed_max\": \"Maximum Wind Speed (m/s)\",\n\n    \"precip_mean\": \"Rainfall / Precipitation (mm)\",\n    \"pressure_mean\": \"Air Pressure (hPa)\",\n    \"dewpoint_mean\": \"Dew Point (Â°C)\",\n    \"cloud_cover_mean\": \"Cloud Cover (%)\",\n\n    \"fire_weather_index\": \"Fire Weather Index (higher = riskier)\"\n}\n\nslider_info = {\n    \"temp_mean\": \"Cold âŸµ  âŸ¶ Hot\",\n    \"temp_max\": \"Lower max âŸµ  âŸ¶ Higher max\",\n    \"temp_min\": \"Colder nights âŸµ  âŸ¶ Warmer nights\",\n\n    \"humidity_mean\": \"Drier âŸµ  âŸ¶ More humid\",\n    \"humidity_min\": \"Very dry âŸµ  âŸ¶ Less dry\",\n    \"humidity_max\": \"Less humid âŸµ  âŸ¶ More humid\",\n\n    \"wind_speed_max\": \"Lower gusts âŸµ  âŸ¶ Stronger gusts\",\n\n    \"precip_mean\": \"Drier âŸµ  âŸ¶ Wetter\",\n    \"pressure_mean\": \"Lower âŸµ  âŸ¶ Higher\",\n    \"dewpoint_mean\": \"Drier air âŸµ  âŸ¶ Moister air\",\n    \"cloud_cover_mean\": \"Clearer âŸµ  âŸ¶ Cloudier\",\n\n    \"fire_weather_index\": \"Lower danger âŸµ  âŸ¶ Higher danger\"\n}\n\n# Slider ranges/defaults (rounded) + steps (integers or 1 decimal max)\nranges, defaults, steps = {}, {}, {}\nfor col in slider_features:\n    lo = float(X_train[col].quantile(0.01))\n    hi = float(X_train[col].quantile(0.99))\n    mid = float(X_train[col].median())\n\n    lo = round(lo, 1)\n    hi = round(hi, 1)\n    mid = round(mid, 1)\n\n    span = hi - lo\n    step = 1.0 if span >= 20 else 0.1  # whole numbers for wide ranges, else 1 decimal\n\n    ranges[col] = (lo, hi)\n    defaults[col] = mid\n    steps[col] = step\n\ndef make_theme_css(mode: str) -> str:\n    if mode == \"Night\":\n        accent = \"#2f80ff\"\n        accent2 = \"#00c2ff\"\n        bg1 = \"#07101b\"\n        bg2 = \"#05060a\"\n        panel = \"rgba(10, 18, 32, 0.88)\"\n        border = \"rgba(47, 128, 255, 0.28)\"\n        chip_bg = \"linear-gradient(90deg, #2f80ff 0%, #00c2ff 100%)\"\n    else:\n        accent = \"#ff6a00\"\n        accent2 = \"#ff3d00\"\n        bg1 = \"#2a160f\"\n        bg2 = \"#0b0b0d\"\n        panel = \"rgba(18, 22, 30, 0.88)\"\n        border = \"rgba(255, 106, 0, 0.24)\"\n        chip_bg = \"linear-gradient(90deg, #ff6a00 0%, #ff3d00 100%)\"\n\n    return f\"\"\"\n    <style>\n      html, body {{\n        background: radial-gradient(circle at top, {bg1} 0%, {bg2} 65%, #000 100%) !important;\n      }}\n\n      .gradio-container {{\n        background: radial-gradient(circle at top, {bg1} 0%, {bg2} 65%, #000 100%) !important;\n        color: #f3f4f6 !important;\n      }}\n\n      .block, .gr-box, .gr-panel, .gr-group, .gr-form, .wrap {{\n        background: {panel} !important;\n        border: 1px solid {border} !important;\n        box-shadow: 0 10px 30px rgba(0,0,0,0.28) !important;\n      }}\n\n      /* Label chips (section headers like \"Time of Day\", slider labels, etc.) */\n      label > span, .label, .gr-label, .label-wrap span, .wrap .label span {{\n        background: {chip_bg} !important;\n        color: #fff !important;\n        border-radius: 10px !important;\n        padding: 4px 10px !important;\n        font-weight: 800 !important;\n      }}\n\n      /* Predict button (force override) */\n      button.primary, .gr-button-primary, button[variant=\"primary\"] {{\n        background: {chip_bg} !important;\n        border: none !important;\n        color: #fff !important;\n        font-weight: 800 !important;\n      }}\n\n      /* Sliders */\n      input[type=\"range\"]::-webkit-slider-thumb {{\n        background: {accent} !important;\n      }}\n      input[type=\"range\"]::-webkit-slider-runnable-track {{\n        background: linear-gradient(90deg, {accent} 0%, rgba(255,255,255,0.22) 65%) !important;\n      }}\n\n      /* Radio buttons: consistent day/night styling WITHOUT messing other components */\n      .gr-radio label {{\n        display: inline-flex !important;\n        align-items: center !important;\n        gap: 10px !important;\n        border: 1px solid {border} !important;\n        border-radius: 12px !important;\n        padding: 8px 12px !important;\n        margin-right: 10px !important;\n        background: rgba(255,255,255,0.04) !important;\n        cursor: pointer !important;\n      }}\n      .gr-radio label span {{\n        color: #e5e7eb !important;\n        font-weight: 800 !important;\n      }}\n      .gr-radio input[type=\"radio\"] {{\n        accent-color: {accent} !important;\n      }}\n      /* Checked state (works on older DOMs too) */\n      .gr-radio label input[type=\"radio\"]:checked + span,\n      .gr-radio label input[type=\"radio\"]:checked ~ span {{\n        color: #fff !important;\n      }}\n      .gr-radio label:has(input[type=\"radio\"]:checked) {{\n        background: {chip_bg} !important;\n        border: none !important;\n      }}\n    </style>\n    \"\"\"\n\ndef predict_fire(day_or_night, *values):\n    user_vals = dict(zip(slider_features, values))\n\n    row_dict = {c: float(X_train[c].median()) for c in feature_cols}\n\n    if has_daynight:\n        row_dict[\"daynight_N\"] = 1.0 if day_or_night == \"Day\" else 0.0\n\n    for k, v in user_vals.items():\n        row_dict[k] = float(v)\n\n    row = pd.DataFrame([row_dict], columns=feature_cols)\n    proba_fire = float(rf_model.predict_proba(row)[0, 1])\n\n    label = \"ðŸ”¥ Fire likely\" if proba_fire >= 0.5 else \"âœ… No fire likely\"\n    percent = f\"{proba_fire * 100:.1f}%\"\n    return label, percent\n\nbase_theme = gr.themes.Soft(primary_hue=\"orange\", secondary_hue=\"red\", neutral_hue=\"slate\")\n\nwith gr.Blocks(theme=base_theme) as demo:\n    theme_html = gr.HTML(value=make_theme_css(\"Day\"))\n\n    gr.Markdown(\"# ðŸ”¥ Wildfire Likelihood Simulator\")\n    gr.Markdown(\"Adjust weather conditions and choose **Day/Night**. Click **Predict** for probability.\")\n\n    with gr.Row():\n        with gr.Column(scale=1):\n            gr.Markdown(\"### Controls\")\n\n            daynight = gr.Radio(\n                choices=[\"Day\", \"Night\"],\n                value=\"Day\",\n                label=\"Time of Day\"\n            )\n\n            slider_inputs = []\n            for col in slider_features:\n                lo, hi = ranges[col]\n                slider_inputs.append(\n                    gr.Slider(\n                        minimum=lo,\n                        maximum=hi,\n                        value=defaults[col],\n                        step=steps[col],\n                        label=friendly_label.get(col, col),\n                        info=slider_info.get(col, \"Low âŸµ  âŸ¶ High\")\n                    )\n                )\n\n        with gr.Column(scale=1):\n            gr.Markdown(\"### Output\")\n            out_label = gr.Textbox(label=\"Prediction\", interactive=False)\n            out_prob = gr.Textbox(label=\"Probability of Fire (%)\", interactive=False)\n            predict_btn = gr.Button(\"Predict\", variant=\"primary\")\n\n    daynight.change(fn=make_theme_css, inputs=daynight, outputs=theme_html)\n    predict_btn.click(fn=predict_fire, inputs=[daynight] + slider_inputs, outputs=[out_label, out_prob])\n\ndemo.launch(debug=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T21:35:29.121315Z","iopub.execute_input":"2026-01-13T21:35:29.122003Z"}},"outputs":[],"execution_count":null}]}